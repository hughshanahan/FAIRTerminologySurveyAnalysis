\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\providecommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{}
    \pretitle{\vspace{\droptitle}}
  \posttitle{}
    \author{}
    \preauthor{}\postauthor{}
    \date{}
    \predate{}\postdate{}
  
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}

\begin{document}

\textbf{Roughly half of people attending the meeting submitted to
this\ldots{}}
\includegraphics{analysis_files/figure-latex/unnamed-chunk-2-1.pdf}

\textbf{A small number are representing their organisation's opionions}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-3-1.pdf}

\textbf{There is a wide spread of roles}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-4-1.pdf}

\begin{table}[H]
\centering
\begin{tabular}{>{\raggedright\arraybackslash\columncolor{khaki}}p{30em}}
\hline
Other possible role descriptions\\
\hline
Research Data Specialist in the research support unit of university library (including teaching and training activities, policy development, infrastructure support)\\
\hline
I am part of the research data support team at the library in my institution. My role involves planning and coordinating RDM training, planning and coordination the efforts around software source code management and I am also part of the front-office of our institutional data repository.\\
\hline
I am a scientific training officer in the training team at EMBL-EBI. My role involves organising, co-ordinating and running both face-to-face and online courses.\\
\hline
I help to describe the needs of the community\\
\hline
\end{tabular}
\end{table}

\textbf{There is a wide spread of domains}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-6-1.pdf}

\begin{table}[H]
\centering
\begin{tabular}{>{\raggedright\arraybackslash\columncolor{khaki}}p{30em}}
\hline
Other research domains\\
\hline
Library \& Information Science\\
\hline
Information management\\
\hline
Interdisciplinary: Art x Social Science x Information Science\\
\hline
Leiden University is a broad university with seven faculties and I am supporting them all in my role as expert in data management and open access.\\
\hline
I wokr on the meta level\\
\hline
\end{tabular}
\end{table}

\textbf{General agreement that Search for Course Materials is a valid
use case.} The negative comments are below\ldots{}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-8-1.pdf}

\begin{table}[H]
\centering
\begin{tabular}{>{\raggedright\arraybackslash\columncolor{khaki}}p{30em}}
\hline
Reasons why this isn't a valid use case\\
\hline
Yes I want this implemented in TeSS\\
\hline
If this scenario is for researchers, they are more likely to use search, a dynamic search based on the terms they are entering similar to https://vocabs.ands.org.au/vocabs/page/widget\_explorer. If searching is not successful, then yes, this is a reasonable example.\\
\hline
Challenge is the choice of terminology structuring; in this case I would suggest using a thesaurus since that organises knowledge for subsequent retrieval in a hierarchical way (given the mentioning of child/parent terms).\\
\hline
\end{tabular}
\end{table}

\textbf{..and also general agreement that Curriculum design is a valid
use case.} The negative comments are below\ldots{}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-9-1.pdf}

\begin{table}[H]
\centering
\begin{tabular}{>{\raggedright\arraybackslash\columncolor{khaki}}p{30em}}
\hline
Reasons why this isn't a valid use case\\
\hline
I am not sure that the only need/purpose here is an automated scanning of training materials to do the match with the terms in the taxonomy. I think that manual mapping (in both directions )  is also very valid . Trainers can easily map their courses to the taxonomy (in my ideal world)\\
\hline
Maybe. I could use this as a filter to select appropriate texts but I would still need to review the hits to assess the quality/depth of the material. The appearance of terms in a text doesn't guarantee coverage of these topics. I would also find competencies useful when deciding what should go into a course. This would be particularly helpful for new trainers who have not had to deliver training on this topic in the past.\\
\hline
Input: like case 4, the human aspect is important. The FAIR-terminology and -competency framework support a human decision-making process.\\
\hline
It will work best if the instructor skills list is aligned with the FAIR Competency framework using a common form.\\
\hline
This can be a helpful first step to weed out texts that are not what you are looking for, but it can not be the only step to find relevant texts.\\
\hline
\end{tabular}
\end{table}

\textbf{But much less support for the other cases}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-10-1.pdf}
\includegraphics{analysis_files/figure-latex/unnamed-chunk-10-2.pdf}
\includegraphics{analysis_files/figure-latex/unnamed-chunk-10-3.pdf}

\begin{table}[H]
\centering
\begin{tabular}{>{\raggedright\arraybackslash\columncolor{khaki}}p{30em}}
\hline
Reasons why this isn't a valid use case\\
\hline
I don't see the connection between the skills of the data repository managers and the quality of their submitted data sets\\
\hline
Is this aligned with CASRAI CRediT? Seems more appropriate for determining roles re: data sets. Otherwise, I can't see data repository managers doing this often in the current state of things.\\
\hline
Perhaps I am being picky but I don't understand why the quality control on uploaded datasets is done on the users rather the datasets themselves. I think it is reasonable to use the terminology to assess the users' knowledge of the FAIR principles and their applications and training needs. Whether they will answer the survey, that is a different story.\\
\hline
I'd rather implement the terminology into the repository (e.g. uploaders choose contributor and data curation processes roles according to the terminology)\\
\hline
Added value of the terminology in these types of use cases is dubious, since it will not likely be able to replace or even meaningfully complement qualitative evaluation by humans (or even A.I.).\\
\hline
The terminology could potentially be used to survey required skills for repository uploader. However more conditions/explanations need to be added in this use case, e.g. the consent from data onwer for being contacted and participating the survey.\\
\hline
A quality control on uploaded data sets should be inspected directly looking at the data sets.Although it is an interesting proposal to use the terminology to inspect the gaps in training at an institution, I would not implemented in relation to a data repository. Skills check could perhaps be implemented/used by graduate schools or education departments.\\
\hline
\\
\hline
The gap analysis is too implicit. I guess what is meant is that if they have not used skills from the framework it means that they need training on these skills? It would be useful if there would be an easy mechanism for them to also add other skills they have used that we might have missed.\\
\hline
For the FAIR - related job assessment case: limited. Difficulty I feel here is that the use of the terminology might be righteous, but to what extent can we select the best candidate using it? The assumption is that the more the cv contains terms from the terminology, the better the candidate. I would say that the use case is a reasonable example in the case the given suggestions were then to be judged by humans. The situation might occur that an applicant uses a lot of detailed terms, as "cv filling", but knows only the basics, let's call that a false positive. Best structuring would be an ontology, given the relations between different entities within the field. And on a more general level: if an applicant were to apply for a job in this field, are we not automatically within the domain of the FAIR4S terminology? Is this automated job application assessment therefore necessary?

For the Article quality control case: I feel like there are some steps missing. For example: how can we determine the article's quality, given only the used terms for FAIR-related competencies? This has to do with the validity of the tool, i.e. is it measuring the paper's quality, or the overlap the paper shows with the terminology. One is not inherent to the other, i think. My feeling is that in this case, the terminology would have only quantitative impact (i.e.: how many FAIR-related papers have we published) over qualitative content (i.e. how FAIR are our datasets? The step between these two is human-centered; a professional in the field has to judge whether or not quality pursued is obtained. Case 2 and 3 are equivalent in this sense.

For the data repository uploader skill check: absolutely a significant use case, depicting well the interchangeable concept of 'quality': we would always need human judgement. The use of the terminology in this case can support the enhancement of professional skills within the FAIR-framework.\\
\hline
Job assessment: from experience I can say that people use all kind of different terminology to explain what they have done, depending on their background:  community, country, domain etc. Using a terminology this way will enhance biases.

Article quality control: a less certain NO from me than with the CV case but this will only work if people have to fill in templates about their data handling ifyou ask me\\
\hline
\end{tabular}
\end{table}

\textbf{Many interesting suggestions for other use cases - but no real
consensus there}

\begin{table}[H]
\centering
\begin{tabular}{>{\raggedright\arraybackslash\columncolor{khaki}}p{30em}}
\hline
Other possible use case\\
\hline
Linked to the Jobs:  To use it to build a function profile in the function house of an organisation (e.g. the NFU, Netherlands Fededration of University Medical Hospitals)
Also Linked to the Jobs:  Use it to scan job advertisements and/or design job advertisements\\
\hline
A research software example is not included (or maybe one of the data-related examples above can include software). An example of determining an author's FAIR (competency) profile, so scanning their research listed on ORCID as one example.\\
\hline
Perhaps it could also be used by policy makers when formulating RDM policies, whether at funding agencies or at research institutions. The terminology could be used to match policy requirements with skills and competencies needed to fulfill those requirements.\\
\hline
I could not add comments to the question about "FAIR-related job description assessment", so I'll do that here: I see that more on a qualitative level - employers should use the catalogue to write job ads and evaluate applicants.\\
\hline
The terms could be used as tags, or in the context of data management plans. These could be further elaborated in the workshop.\\
\hline
The terminology can be used to identify and generate related job descriptions, in terms of relevant skills required and job activities. However I would not use the terms to assess CVs in an automated way, simply because wording in CVs could vary a lot on describing the same things. 

The terminology could also potentially used in making strategic or tactical institutional RDM roadmap. It can be used to assess the current status of RDM prachtices and determine the next priorities regarding institutional conditions.\\
\hline
Software FAIR\\
\hline
There was no way to add this above so I'm adding it here instead. For the FAIR-related job application assessment: The use of terms in a CV doesn't guarantee the suitability of a candidate. This assumes that all candidates describe their skills and experience in a consistent way. --- For article quality control: Mentioning terms in an article doesn't guarantee that the steps have been taken. Similarly, researchers may not explicitly mention steps they have taken although they have been applied. I can see that this might be used to flag sections of a article that a relevant but using it to judge a paper might be a step too far.\\
\hline
As a librarian I will organise a workshop for researchers related to any of the subjects in the ontology. In my communication related to the workshop (blogs, twitter, LinkedIn, newsletters) I make sure that I use consistent terminology by browsing the ontology for concepts related to the topic I will present.\\
\hline
Case 6a: Finding FAIR and trusted digital repositories
The data-management departement of a mid-sized university would like to provide a list of preferred repositories for their researchers to deposit data. The university has a number of standards which the repositories have to fulfil. These not only cover the repositoriesâ€™ trustworthiness (TDRs) but to a large extent also concern the FAIR maturity level. Using the terms within the terminology and entering them in an online repository finder tool, the data-management department finds the most suitable and mature repositories.   

Case 6b: Ensuring research output is FAIR, for TDR's 
As a leading researcher in the field of information and data sciences, I am responsible and accountable for your research areas activities and behaviour. I am aware of legal and ethical aspects of the research you conduct, including the FAIR-principles that make your and your team's outputs FAIR. My knowledge and understanding of the FAIR terminology and the FAIR4S framework enables you to fulfil the synergetic role of intermediary between research outputs on the one hand, and trusted repositories on the other hand.\\
\hline
\end{tabular}
\end{table}

\textbf{Use cases that would be used reflects the above}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-12-1.pdf}

\textbf{Thesaurus is favoured}

\includegraphics{analysis_files/figure-latex/unnamed-chunk-13-1.pdf}

\begin{table}[H]
\centering
\begin{tabular}{>{\raggedright\arraybackslash\columncolor{khaki}}p{30em}}
\hline
Reasons for choosing Controlled Vocabulary\\
\hline
I must say I found it difficult to decide as I'm not a specialist on this type of work, but it seems to make sense to make it "accessible to computational querying and reasoning".\\
\hline
to keep it simple and widely applicable. I find it more important to educate people on the meaning and correct use of the terminology.\\
\hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{>{\raggedright\arraybackslash\columncolor{khaki}}p{30em}}
\hline
Reasons for choosing Ontology\\
\hline
Facilitates interoperability between different languages.\\
\hline
It is hard to select one out of the three options. They all contribute to building the FAIR competences for different purpose. Before going into details in CV or thesaurus, it is important to have a holistic overview of everything within the working scope. That's the only reason I chose ontology, but again I would not leave the other 2 aspects/components out.\\
\hline
Given the generic nature of ontologies - containing entities of a certain domain, thesauri and controlled vocabularies might become part of an ontology of FAIR terminologies. In constructing an Ontology, FAIR-terminology can also be made Linked-Web-Ready, for example when abiding to RDF-rules and semantic interoperability. This can then be linked back to the I in FAIR, for both machines and humans. This two-way-interoperability is the reason that I, in my earlier answers, emphasised the human factor in the use cases.\\
\hline
Looking at what the use cases aim for, you do need to make sure that you don't flatten the complexity too much\\
\hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{>{\raggedright\arraybackslash\columncolor{khaki}}p{30em}}
\hline
Reasons for choosing Thesearus\\
\hline
because I would like it to be able to show related terms, so be a bit broader that only the controlled vocabulary\\
\hline
I initially chose ontology since it seems that relationships between the competencies can become very rich but decided on a thesaurus as it seemed like a simpler approach to take where it is more accessible to the research community and helps with scoping the initial work (instead of maybe getting carried away with the ontology which requires more work).\\
\hline
For the use cases I selected a Thesaurus seems to be the most complete, but at the same time the simplest solution from these options.\\
\hline
Speed of development and flexibility of use.\\
\hline
Building a formal model of the domain can become complex and cumbersome.\\
\hline
\end{tabular}
\end{table}

\textbf{Overall people seem okay with the top concepts (Scope and
Resource)}
\includegraphics{analysis_files/figure-latex/unnamed-chunk-14-1.pdf}

\begin{table}[H]
\centering
\begin{tabular}{>{\raggedright\arraybackslash\columncolor{khaki}}p{30em}}
\hline
Other possible top level concepts\\
\hline
Data management planning should be stressed more. Issues under the 'Scope and resource' theme are important, but shouldn't necessarily be grouped under this particular heading. Overall, this terminology exercise as described in this questionnaire feels forced and in certain aspects somewhat alien to actual realities of research and RDM.\\
\hline
It really depends on the specific role how important the different concepts are\\
\hline
\end{tabular}
\end{table}


\end{document}
